---
title: "Lab 7: Neighborhood Segregation"
subtitle: <h4 style="font-style:normal">CRD 150 - Quantitative Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
date: <h4 style="font-style:normal">February 21, 2020</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    mathjax: local
    theme: cosmo
    code_folding: show
---



<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>


<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>

\

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this guide you will learn how to calculate neighborhood segregation, diversity, and concentration measures using R.  The objectives of the guide are as follows

1. Calculate the following measures of regional level racial residential segregation: Dissimilarity, Interaction and Entropy
2. Calculate the following measures of neighborhood level racial diversity and concentration: Entropy scores and Location Quotients

To accomplish these objectives, you will be working with Census tract data for the six largest metropolitan areas in California: Los Angeles, San Diego, San Jose, San Francisco, Fresno, and Sacramento.

This lab guide follows closely and supplements the material presented in class Handout 4.


<p class="comment", style="font-style:normal">**Assignment 7 is due by 11:59 pm, February 27th on Canvas.**  See [here](https://crd150.github.io/hw_guidelines.html) for assignment guidelines.  You must submit an `.Rmd` file and its associated `.html` file. Name the files: yourLastName_firstInitial_asgn07. For example: brazil_n_asgn07.</p>



<div style="margin-bottom:25px;">
</div>
## **Open up a R Markdown file**
\

Download the [Lab template](https://raw.githubusercontent.com/crd150/data/master/labtemplate.Rmd) into an appropriate folder on your hard drive (preferably, a folder named 'Lab 7'), open it in R Studio, and type and run your code there.  Change the title ("Lab 7") and insert your name and date. Don't change anything else inside the YAML (the stuff at the top in between the `---`).  Also keep the grey chunk after the YAML. 

<div style="margin-bottom:25px;">
</div>
## **Installing and loading packages**
\

We will not be using any new packages in this lab.  Hooray!

You’ll need to load the following packages. Unlike installing, you will always need to load packages whenever you start a new R session. You’ll also always need to use `library()` in your R Markdown file.

```{r message = FALSE, warning=FALSE}
library(sf)
library(sp)
library(tidyverse)
library(tidycensus)
library(tigris)
options(tigris_class = "sf")
library(tmap)
library(rmapshaper)
```


<div style="margin-bottom:25px;">
</div>
## **Bringing in tract data**
\

The following code uses the Census API to bring in demographic and socioeconomic tract-level data for the six most populated metropolitan areas in California: Los Angeles, San Diego, San Jose, San Francisco, Fresno, and Sacramento.  We won't go through each line of code in detail because we've covered all of these operations and functions in prior labs.  We've embedded comments within the code that briefly explains what each chunk is doing. Go back to prior guides (or RDS/GWR) if you need further help. 

```{r include=FALSE, warning=FALSE, results="hide"}
census_api_key("b81d373d6e785ecbc489de1fc862aef424d0a63a")
```

```{r eval=FALSE, warning=FALSE}
census_api_key("YOUR API KEY GOES HERE")
```

```{r warning=FALSE, results="hide", message=FALSE}

# Bring in census tract data using the Census API 
ca.tracts <- get_acs(geography = "tract", 
              year = 2017,
              variables = c(tpop = "B01003_001", tpopr = "B03002_001", 
                            nhwhite = "B03002_003", nhblk = "B03002_004",
                            nhasn = "B03002_006", hisp = "B03002_012"),
              state = "CA",
              survey = "acs5",
              geometry = TRUE)

# Make the data tidy, calculate and keep essential vars. Also take out zero population tracts
ca.tracts <- ca.tracts %>% 
  select(-(moe)) %>%
  spread(key = variable, value = estimate) %>%
  mutate(pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
        pnhblk = nhblk/tpopr, phisp = hisp/tpopr, oth = tpopr - (nhwhite+nhblk+nhasn+hisp), 
        poth = oth/tpopr, nonwhite = tpopr-nhwhite, pnonwhite = nonwhite/tpopr) %>%
  select(c(GEOID,tpop, tpopr, pnhwhite, pnhasn, pnhblk, phisp,
           nhwhite, nhasn, nhblk, hisp, nonwhite, pnonwhite, oth, poth))  %>%
  filter(tpop != 0)

# Bring in metro area boundary
cb <- core_based_statistical_areas(cb = TRUE)

# Keep six largest metros in CA
large.metros <- filter(cb, grepl(c("Sacramento|Los Angeles|San Diego|San Jose|San Francisco|Fresno"), NAME))

#Keep tracts in large metros. Drop unnecessary variables
large.tracts <- st_join(ca.tracts, large.metros, join = st_within, left=FALSE) %>%
                select(-(c(ALAND, AWATER, AFFGEOID)))
```

<div style="margin-bottom:25px;">
</div>
## **Residential segregation**
\

Measures of segregation and other indices of place-based inequality have been fundamental to documenting and understanding the causes and consequences of residential patterns of racial separation. Let's calculate the two most common measures of racial segregation: Dissimilarity, which captures residential evenness, and Interaction, which measures exposure.  

<div style="margin-bottom:25px;">
</div>
### **Dissimilarity Index**
\

The most common measure of residential evenness is the Dissimilarity Index *D*. To calculate *D*, we'll follow the Dissimilarity index formula on page 2 of Handout 4. We will calculate Black/White, Hispanic/White, Asian/White, and non-White/White Dissimilarity. We first need to calculate the total population by race/ethnicity for each metro. This is the value $T_m$ and $T_k$ in the formula.   We do this by using the `group_by()` and `mutate()` functions.  

```{r warning = FALSE, message = FALSE}
large.tracts <- large.tracts %>%
      group_by(NAME) %>%
      mutate(nhwhitec = sum(nhwhite), nonwhitec = sum(nonwhite), 
             nhasnc = sum(nhasn), nhblkc = sum(nhblk), othc = sum(oth),
             hispc = sum(hisp), tpoprc = sum(tpopr)) %>%
      ungroup()
```  
  
The `group_by()` function tells R that all future functions on *large.tracts* will be grouped according to the variable *NAME*, which is the metro name. We use the `sum()` function within the `mutate()` function to sum up, for example, the non-Hispanic white population *nhwhite* for each metro. We name this variable *nhwhitec*.  If you type in `View(large.tracts)`, you should find that the variable *nhwhitec* provides the same value for all tracts within the same metro. We do this for all the other race/ethnic groups.

The function `ungroup()` at the end of the code tells R to stop the grouping.  For example, we see the results after grouping by *NAME* 

```{r warning = FALSE, message = FALSE}
large.tracts %>%
    group_by(NAME)
```

that the tibble *large.tracts* is grouped (*Groups:   NAME [6]*).  Use `ungroup()` to, well, ungroup the tibble.

```{r warning = FALSE, message = FALSE}
large.tracts %>%
    group_by(NAME) %>%
    ungroup()
```

and the grouping is gone!  It's always good practice to `ungroup()` a data set if you are saving it for future use (rather than using it as a summary table as we've doing so far in the class).

We've got the values for $T_m$, $T_k$, $t_{im}$, and $t_{ik}$, so we can calculate the rest of the formula, breaking it down piece-by-piece like we did in the handout and in class. The following code calculates the Dissimilarity indices 

```{r warning = FALSE, message = FALSE}
large.tracts %>%
      group_by(NAME) %>%
      mutate(d.wb = abs(nhblk/nhblkc-nhwhite/nhwhitec),
              d.wa = abs(nhasn/nhasnc-nhwhite/nhwhitec), 
              d.wh = abs(hisp/hispc-nhwhite/nhwhitec),
              d.wnw = abs(nonwhite/nonwhitec-nhwhite/nhwhitec)) %>%
      summarize(BWD = 0.5*sum(d.wb, na.rm=TRUE), AWD = 0.5*sum(d.wa, na.rm=TRUE),
                HWD = 0.5*sum(d.wh, na.rm=TRUE), NWWD = 0.5*sum(d.wnw, na.rm=TRUE))
```

<br>

Let's break the code down so we're all on the same page. We use `mutate()` to calculate the tract level contributions to the index, i.e. the value $\left|\frac{t_{rm}}{T_m} - \frac{t_{rk}}{T_k}\right|$ for each neighborhood $i$.  Next, we turn to `summarize()` to finish the rest of the job.  Within `summarize()`, we use the function `sum()` to add the neighborhood specific values in Equation 1 in Handout 4. In other words, `sum()` is performing the $\sum\limits_{i}^{N}$ that adds up $\left|\frac{t_{rm}}{T_m} - \frac{t_{rk}}{T_k}\right|$. Finally, multiply the summed up value by 0.5 to get the final indices.

<br>

The resulting values provide the Dissimilarity indices for Black/White (*BWD*), Asian/White (*AWD*), Hispanic/White (*HWD*), Nonwhite/White (*NWWD*).  In all of these cases, we calculate segregation from white residents, but you can calculate segregation for any race/ethnicity combination (e.g. Black/Hispanic).  Instead of just copying and pasting the chunk of code above into your console, make sure you understand what each line of code is doing.  Not only will it help you become a more seasoned R coder, but it will also help you better understand the underlying math behind the Dissimilarity index.

<br>

The Dissimilarity index for Black/White in Sacramento is 0.572.  The interpretation of this value is that 57.2% of black residents would need to move neighborhoods in order to achieve a uniform distribution of black residents across neighborhoods.  How does this value compare to the other large California metropolitan areas? What about the metropolitan areas listed in the Logan and Stults reading?

<div style="margin-bottom:25px;">
</div>
### **Interaction Index**
\

The most common measure of exposure is the Interaction Index $P^*$.  Let's calculate the exposure of black (*BWI*), Asian (*AWI*), Hispanic (*HWI*), and Non-white (*NWWI*) residents to white residents using the formula on page 3 of Handout 4.

```{r}
large.tracts %>%
      group_by(NAME) %>%
      mutate(i.wb = (nhblk/nhblkc)*(nhwhite/tpopr),
              i.wa = (nhasn/nhasnc)*(nhwhite/tpopr), 
              i.wh = (hisp/hispc)*(nhwhite/tpopr),
              i.wnw = (nonwhite/nonwhitec)*(nhwhite/tpopr)) %>%
      summarize(BWI = sum(i.wb, na.rm=TRUE), AWI = sum(i.wa, na.rm=TRUE),
                HWI = sum(i.wh, na.rm=TRUE), NWWI = sum(i.wnw, na.rm=TRUE))
```                
                
The `mutate()` function is creating the tract specific values $\frac{t_{im}}{T_m} * \frac{t_{ik}}{t_i}$.  We then turn to `summarize()` to perform the $\sum\limits_{i}^{N}$. 

The probability of a black resident "interacting" with a white person in his or her neighborhood is about 36.0% in Sacramento. We can also interpret this to mean that 36 of every 100 people a black person meets in his or her neighborhood will be white.  Remember that interaction is not symmetric.  Calculate the interaction of white residents with black residents in the metro areas and see if there are major differences with the values we calculated above.

<div style="margin-bottom:25px;">
</div>
### **Multigroup Entropy Index**
\

The Dissimilarity and Interaction indices are measures of segregation between two groups.  The Entropy index is a multigroup measure of segregation.  This index is a measure of evenness.  

We learned in Handout 4 that there are basically three steps to calculating the Entropy index.  First, you calculate Entropy scores at the neighborhood level. This is Equation 3 in Handout 4. Remember, we'll need to convert $p_{ir}$$log(1/p_{ir})$ to 0 if $p_{ir}$ is equal to 0. When $p_{ir}$  is equal to 0, we get an `NaN` value for $log(1/p_{ir})$.  NaN means "Not a Number." We use the`replace()` and `is.nan()` functions to convert the `NaN` to a 0.

```{r}
large.tracts <- large.tracts %>%
      mutate(e1 =  pnhwhite*log(1/pnhwhite), e2 = pnhasn*log(1/pnhasn),
             e3 = pnhblk*log(1/pnhblk), e4 = phisp*log(1/phisp),
             e5 = poth*log(1/poth), 
            e1 = replace(e1, is.nan(e1), 0), e2 = replace(e2, is.nan(e2), 0),
            e3 = replace(e3, is.nan(e3), 0), e4 = replace(e4, is.nan(e4), 0),
            e5 = replace(e5, is.nan(e5), 0),
            ent = e1 + e2 + e3 + e4 +e5) %>%
      select(-c(e1:e5))
```

In the `mutate()` function, the first set of `e1 =` to `e5 =` arguments calculates $p_{ir} log(\frac{1}{p_{ir}})$ for each race/ethnic group.  The next set of `e1 =` to `e5 =` arguments replaces any values with an *NaN* with a 0.  The variable *ent* sums up  the individual race/ethnic values (i.e. performs the $\sum\limits_{r = 1}^{r}$) to obtain the neighborhood entropy score.

You then need to calculate Entropy scores at the metro level.  This is Equation 4 in the handout. We need to calculate the metro level race/ethnic proportions $p_r$. Then the `e1 =` to `e5 =` arguments calculate $p_{r} log(\frac{1}{p_{r}})$ for each race/ethnic group and replaces *NaN* with a 0. Finally we calculate the metro level entropy score `entc =` by performing the $\sum\limits_{r = i}^{r}$.

```{r}
large.tracts <- large.tracts %>%
      group_by(NAME) %>%
      mutate(pnhwhitec = nhwhitec/tpoprc, pnhasnc = nhasnc/tpoprc, 
             pnhblkc = nhblkc/tpoprc, pothc = othc/tpoprc, phispc = hispc/tpoprc,
             e1 =  pnhwhitec*log(1/pnhwhitec), e2 = pnhasnc*log(1/pnhasnc),
             e3 = pnhblkc*log(1/pnhblkc), e4 = phispc*log(1/phispc),
             e5 = pothc*log(1/pothc), 
            e1 = replace(e1, is.nan(e1), 0), e2 = replace(e2, is.nan(e2), 0),
            e3 = replace(e3, is.nan(e3), 0), e4 = replace(e4, is.nan(e4), 0),
            e5 = replace(e5, is.nan(e5), 0),
            entc = e1 + e2 + e3 + e4 +e5) %>%
      select(-c(e1:e5)) %>%
      ungroup()
```

Finally, we calculate the Entropy index for each metro area. This is Equation 5 in the handout.

```{r}
large.tracts %>%
      group_by(NAME) %>%
      summarize(H = sum((tpopr*(entc-ent)/(entc*tpoprc)), na.rm = TRUE))
```

Remember that the Entropy index goes from 0 to 1, with 0 indicating complete integration and 1 indicating complete segregation. Which metro is the most segregated? Least segregated? 

<div style="margin-bottom:25px;">
</div>
## **Neighborhood Diversity and Concentration**
\

The Dissimilarity, Interaction and Entropy indices are metro area (or city, county, ...) indices. In the handout, we covered two neighborhood level measures: Entropy score, which captures neighborhood racial/ethnic diversity, and the Location Quotient, which captures neighborhood racial/ethnic concentration.  A city may be highly segregated, but still exhibit diversity at the neighborhood level. The opposite can also happen.  Here's a nice [article](https://fivethirtyeight.com/features/the-most-diverse-cities-are-often-the-most-segregated/) that discusses city vs. neighborhood differences in diversity.

<div style="margin-bottom:25px;">
</div>
### **Entropy Score**
\

We already calculated the entropy score above. Because we used 5 race/ethnic groups, maximum entropy is

```{r}
log(5)
```

The higher the value, the greater the diversity.  We can create a faceted map of neighborhood entropy for our 5 metro areas 

```{r message = FALSE, warning = FALSE}
tm_shape(large.tracts, unit = "mi") +
  tm_polygons(col = "ent", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "Entropy score") +
    tm_facets(by = "NAME", free.coords = TRUE)+
    tm_style("grey")
```

You can play around with the map to make the labels more readable.   You can also use `tmap_mode("view")` to zoom in.  Using either the map or, perhaps, the `arrange()` function, can you identify the least and most diverse neighborhoods in each metropolitan area?

<div style="margin-bottom:25px;">
</div>
### **Location Quotient**
\

The Location Quotient for Racial Residential Segregation (LQRSS) is effectively a measure of concentration.  Let's zoom into the Los Angeles metropolitan area and calculate the LQ for each of its tracts.  First, keep Los Angeles metro from *large.tracts* using the `filter()` command and calculate the LQ for blacks, Asians, Hispanics, and non-whites (equation 6 in Handout 4).

```{r}
la.tracts <- large.tracts %>%
  filter(NAME == "Los Angeles-Long Beach-Anaheim, CA") %>%
  mutate(blklq = pnhblk/pnhblkc, 
        asnlq = pnhasn/pnhasnc,
        hisplq = phisp/phispc,
        nonwhitelq = pnonwhite/(nonwhitec/tpoprc))
```

The first census tract with *GEOID* of 06037101110 has a black LQ of 0.18.  In your own words, describe what this value represents?

You can visualize the distribution using a histogram (or boxplot).  For example, a histogram of the black LQ looks like

```{r warning=FALSE, message = FALSE}
la.tracts %>% 
  ggplot() + 
    geom_histogram(mapping = aes(x=blklq), na.rm=TRUE) +
    xlab("Black Location Quotient") 
```

The skewness of the distribution indicates significant concentration of the black population in Los Angeles. We can also map the LQRSS

```{r warning = FALSE, message=FALSE}
tmap_mode("view")
tm_shape(la.tracts, unit = "mi") +
  tm_polygons(col = "blklq", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "Black Location Quotient") 
```

The map indicates that there are some neighborhoods in the metro that have a percent non-Hispanic black population that is as high as 13.5 times the overall percent non-Hispanic black population in the metro area. Holy Moly!

Map the LQRSSs for Sacramento metro.  How does it visually compare with the Los Angeles map? What about the other metro areas?


<div style="margin-bottom:25px;">
</div>
## **Assignment 7**
\

Assignment 7 will be posted here Friday morning


***

Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)

