---
title: "Lab 4: Spatial Data in R"
subtitle: <h4 style="font-style:normal">CRD 150 - Quantitative Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
date: <h4 style="font-style:normal">January 31, 2020</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    mathjax: local
    theme: cosmo
    code_folding: show
---



<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>


<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

In this guide you will acquire the skills needed to process and present spatial data in R.  The objectives of the guide are as follows 


1. Understand how spatial data are processed in R
2. Learn basic operations on polygon shapefile data
3. Learn how to make a map in R

This guide focuses exclusively on polygon or areal data.  You will have the opportunity to handle and examine point data in Lab 6. This lab guide follows closely and supplements the material presented in Chapters 2.1, 2.2, and 8 in the textbook [Geocomputation with R](https://geocompr.robinlovelace.net/) (GWR).  

<br>

<p class="comment", style="font-style:normal">**Assignment 4 is due by 11:59 pm, February 6th on Canvas.**  See [here](https://crd150.github.io/hw_guidelines.html) for assignment guidelines.  You must submit an `.Rmd` file and its associated `.html` file. Name the files: yourLastName_firstInitial_asgn04. For example: brazil_n_asgn04.</p>


<div style="margin-bottom:25px;">
</div>
## **Open up a R Markdown file**
\

Download the [Lab template](https://raw.githubusercontent.com/crd150/data/master/labtemplate.Rmd) into an appropriate folder on your hard drive (preferably, a folder named 'Lab 4'), open it in R Studio, and type and run your code there.  Change the title ("Lab 4") and insert your name and date. Don't change anything else inside the YAML (the stuff at the top in between the `---`).  Also keep the grey chunk after the YAML. For a rundown on the use of R Markdown in labs, see [Lab 1](https://crd150.github.io/lab1.html)

<div style="margin-bottom:25px;">
</div>
## **Installing and loading packages**
\

You’ll need to install the following packages in R. You only need to do it once, so if you’ve already installed these packages, skip the code. Also, don’t put these `install.packages()` commands in your R Markdown document. Copy and paste the code in the R Console. We’ll talk about what these packages provide as their relevant functions come up in the guide

```{r message = FALSE, warning = FALSE, eval=FALSE}
install.packages("sf")
install.packages("tigris")
install.packages("tmap")
```

You’ll need to load the following packages using `library()`. Unlike installing, you will always need to load packages whenever you start a new R session. 

```{r message = FALSE, warning=FALSE}
library(tidyverse)
library(tidycensus)
library(sf)
library(tigris)
#you need to let R know to bring in the spatial data as sf objects
options(tigris_class = "sf")
library(tmap)
```


<div style="margin-bottom:25px;">
</div>
## **Spatial data in R**
\

The main package we will use for dealing with spatial data in R is the tidy friendly **sf** package.  **sf** stands for simple features.  What is a feature? A feature is thought of as a thing, or an object in the real world, such as a building or a tree.  A county can be a feature. As can a city and a neighborhood.  Features have a geometry describing where on Earth the features are located, and they have attributes, which describe other properties. Think back to [Lab 2](https://crd150.github.io/lab2.html) - we were working with counties.  The difference between what we were doing then and what we will be doing in this lab is that counties in Lab 2 had attributes (e.g. percent Hispanic, total population), but they did not have geometries. As such, we could not put them on a map because we don't have their specific geographic coordinates. This is what separates nonspatial and spatial data in R.  

<div style="margin-bottom:25px;">
</div>
## **Bringing in spatial data**
\

**sf** is the specific type of data object that deals with spatial information in R. Think back to [Lab 1](https://crd150.github.io/lab1.html) when we discussed the various ways R stores data - **sf** is just another way.  But please note that spatial data themselves outside of R can take on many different formats. We'll be primarily working with shapefiles in this class.  [Shapefiles](https://en.wikipedia.org/wiki/Shapefile) are not the only type of spatial data, but they are the most commonly used. Let's be clear here: **sf** objects are R specific and shapefiles are a general format of spatial data.  This is like tibbles are R specific and csv files are a general format of non spatial data. 

We will be working with census geographies in this lab (and pretty much all future labs). There are two major packages for bringing in Census shapefiles into R: **tidycensus** and **tigris**.  These packages allow users to directly download and use [TIGER Line shapefiles](https://www.census.gov/geo/maps-data/data/tiger-line.html) from the Census Bureau.

<div style="margin-bottom:25px;">
</div>
### **tidycensus**
\

Back in Week 2's lab, we worked with the **tidycensus** package and the Census API to bring in Census data into R.  Fortunately, we can use the same commands to bring in Census geographic data.  Use the `get_acs()` command to bring in California tract-level median household income, total foreign-born population, and total population.  Remember to use your Census API key.  

```{r include=FALSE, warning=FALSE, results="hide"}
census_api_key("b81d373d6e785ecbc489de1fc862aef424d0a63a")
```

```{r eval=FALSE, warning=FALSE, results="hide"}
census_api_key("YOUR API KEY GOES HERE")
```

```{r warning=FALSE, results="hide", message=FALSE}
ca.tracts <- get_acs(geography = "tract", 
              year = 2017,
              variables = c(medincome = "B19013_001", 
                            fb = "B05012_003", totp = "B05012_001"), 
              state = "CA",
              survey = "acs5",
              geometry = TRUE)
```

The only difference between the code above and what we used in Lab 2 is we have one additional argument added to the `get_acs()` command: `geometry = TRUE`.  This command tells R to bring in the spatial features associated with the geography you specified in the command, in our case California tracts. Type in *ca.tracts* to see what we've got.

```{r}
ca.tracts
```

<br>

The object looks much like a basic tibble, but with a few differences.  

* You'll find that the description of the object now indicates that it is a simple feature collection with 5 fields (attributes or columns of data).  
* The `geometry_type` indicates that the spatial data are in `MULTIPOLYGON` form (as opposed to points or lines, the other basic vector data forms, which were discussed in OSU Ch. 1).  
* `bbox` stands for bounding box, which indicates the spatial extent of the features (from left to right, for example, California tracts go from a longitude of -124.4096 to -114.1312).  
* `epsg` and `proj4string` are related to the coordinate reference system, which we'll touch on later in the quarter.  
* The final difference is that the data frame contains the column *geometry*.  The tidy data rule for simple features is: we have a data frame where each feature forms a row. A single column (a list-column) contains the geometry for each observation.  This geometry is what makes this data frame spatial. Remember that a tibble is a data frame. Hence, an **sf** objective is basically a tibble, or has tibble like qualities.  This means that we can use nearly all of the functions we've learned in the past three labs on **sf** objects. Hooray for consistency!

<div style="margin-bottom:25px;">
</div> 
### **tigris package**
\

Another package that allows us to bring in census geographic boundaries is **tigris**.  [Here](https://github.com/walkerke/tigris/blob/master/README.md) is a list of all the geographies you can download through this package. When you loaded this package into R at the top of this lab, you specified the option `tigris_class = "sf"`.  This tells R to bring in shapefiles as **sf** objects (the default is to bring them as **sp** objects, which is another type of spatial object we'll get to in Lab 5).

Let's bring in the boundaries for Sacramento city.  Use the `places()` function to get all places in California.

```{r warning=FALSE, message=FALSE, results = FALSE}
pl <- places(state = "CA", cb = TRUE, year=2017)
```

<br>

The `cb = TRUE`  argument tells R to download a [generalized cartographic boundary](https://www.census.gov/geo/maps-data/data/cbf/cbf_description.html) file, which drastically reduces the size of the data (compare the file size when you don't include `cb = TRUE`) .   The argument `year=2017` tells R to bring in the boundaries for that year (census geographies can change from year to year). When using the multi-year ACS, best to use the end year of the period. In the `get_acs()` command above we used `year=2017`, so also use `year=2017` in the `places()` command.  

We can use `filter()` to keep Sacramento city.

```{r warning=FALSE, message=FALSE, results = FALSE}
sac.city <- filter(pl, NAME == "Sacramento")
sac.city
```

The argument `NAME == "Sacramento"` tells R to keep cities with the exact city name "Sacramento". Note that unlike the **tidycensus** package, **tigris** does not allow you to attach attribute data (e.g. percent Hispanic, total population, etc.) to geometric features.

Let's use use the function `core_based_statistical_areas()` to bring in boundaries for all metro areas in the United States (there is no `state = "CA"` argument available for `core_based_statistical_areas()`) .

```{r warning=FALSE, message=FALSE, results = FALSE}
metro <- core_based_statistical_areas(cb = TRUE, year=2017)
```

To get the Sacramento metropolitan area, we can't use the `NAME == "Sacramento"` argument that we used to get Sacramento city because the metro area is not simply named "Sacramento". In this case, we can use the function `grepl()` within the `filter()` function. 

```{r}
sac.metro <- filter(metro, grepl("Sacramento", NAME))
```

The function `grepl()` tells R to find features (rows) with the value "Sacramento" somewhere in their value for the variable *NAME*. The command `filter()` tells R to keep the rows that `grepl()` found that contained the value "Sacramento". The function `grepl()` is useful when we don't know the full or exact name of an area.  

<div style="margin-bottom:25px;">
</div> 
### **Reading from your hard drive**
\

Directly reading spatial files using an API is great, but doesn't exist for many spatial data sources. You'll often have to download a spatial data set, save it onto your hard drive and read it into R.  The function for reading spatial files as **sf** objects is `st_read()`.

Let's bring in a shapefile I created that contains median income for census tracts in the Sacramento metropolitan area.  I zipped up the file and uploaded it onto Github.  Use the following code to download and unzip the file. 

```{r warning = FALSE, message = FALSE, eval = FALSE}
download.file(url = "https://raw.githubusercontent.com/crd150/data/master/SacramentoMetroTracts.zip", destfile = "SacramentoMetroTracts.zip")
unzip(zipfile = "SacramentoMetroTracts.zip")
```

```{r warning = FALSE, message = FALSE, include = FALSE}
download.file(url = "https://raw.githubusercontent.com/crd150/data/master/SacramentoMetroTracts.zip", destfile = "SacramentoMetroTracts.zip")
unzip(zipfile = "SacramentoMetroTracts.zip")
```

<br>

Don't worry if you don't understand these commands - they are more for you to simply copy and paste so that you can download files that I zipped up and uploaded onto GitHub.  You can look at the help documentation for each function if you are curious.

You should see the *SacMetroTractsIncome* files in your current working directory (type in `getwd()` to find where these files reside on your hard drive). Note that the shapefile is actually not a single file but is represented by multiple files, specifically four files named *SacMetroTractsIncome* with shp, dbf, prj, and shx extensions.  These files are all connected to one another, so don't manually alter these files.  Moreover, if you want to remove a shapefile from your hard drive, delete all the associated files.

Bring in this Sacramento Metropolitan Area tract file using `st_read()`.  You'll need to add the *.shp* extension so that the function knows it's reading in a shapefile.

```{r warning = FALSE, message = FALSE, results = "hide"}
sac.metro.tracts <- st_read("SacMetroTractsIncome.shp", stringsAsFactors = FALSE)
```

The argument `stringsAsFactors = FALSE` tells R to keep any variables that look like a character as a character and not a [factor](https://r4ds.had.co.nz/factors.html), which we won't use much, if at all, in this class.


<div style="margin-bottom:25px;">
</div>
## **Data Wrangling**
\

There is a lot of stuff [behind the curtain](https://r-spatial.github.io/sf/articles/sf1.html) of how R handles spatial data as simple features, but the main takeaway is that **sf** objects are data frames.  This means you can use many of the functions we've learned in the past couple labs to manipulate **sf** objects, and this includes our best buddy the pipe `%>%` operator.  For example, let's do the following data wrangling tasks on *ca.tracts*.

1. Drop the *moe* variable
2. Convert the dataset from long to wide
3. Calculate percent non-Hispanic white

We do all of this in one line of continuous code using the pipe operator `%>%`

```{r results='hide'}
ca.tracts <- ca.tracts %>%
              select(-(moe)) %>%
            spread(key = variable, value = estimate) %>%
            mutate(pfb = fb/totp)
```

Notice that we've already used all of the functions above for nonspatial data wrangling. The main takeaway: **sf** objects are data frames, so you can use many of the functions you've learned in the past couple of labs on these objects.  This includes the function `ggplot()`, which we can use to map the data. We'll cover the use of `ggplot()` for mapping later in this guide.  


<div style="margin-bottom:25px;">
</div>
## **Merging attribute data**
\

Another important operation is to join attribute data to an **sf** object.  For example, let's say you wanted to add tract level percent race/ethnicity, which is located in a csv file I've uploaded on GitHub

```{r warning=FALSE, message=FALSE}
ca.race <- read_csv("https://raw.githubusercontent.com/crd150/data/master/californiatractsrace.csv")
```

Remember, were dealing with data frames here, so we can use `left_join()`, which we covered in [Lab 2](https://crd150.github.io/lab2.html), to join the files *ca.race* and *sac.metro.tracts*

```{r warning=FALSE, message=FALSE}
sac.metro.tracts <- sac.metro.tracts %>%
  left_join(ca.race, by = "GEOID")
sac.metro.tracts
```  

There is a whole set of data wrangling operations specific to spatial data.  We will cover these operations in next week's lab.

<div style="margin-bottom:25px;">
</div>
## **Dropping sf geometry **
\

What if you wanted to work with just the attribute data of an **sf** object? In other words, you want to *unspatialize* it by dropping its geometry.  You might think that we can just select out the *geometry* column using the function `select()`.

```{r warning=FALSE, message=FALSE}
sac.metro.tracts.df <- select(sac.metro.tracts, -geometry)
names(sac.metro.tracts.df)
```

The variable *geometry* is still there!  There is a special **sf** specific function - `st_drop_geometry()` - that allows you to eliminate the geometry from the data frame. 

```{r warning=FALSE, message=FALSE}
sac.metro.tracts.df <- st_drop_geometry(sac.metro.tracts)
names(sac.metro.tracts.df)
```

The function turns it into a regular data frame.

```{r warning=FALSE, message=FALSE}
class(sac.metro.tracts.df)
```

Remember that the tidyverse likes tibbles, so use the `as_tibble()` function we first encountered in [Lab 1](https://crd150.github.io/lab1.html) to convert the regular data frame into a tibble.

<div style="margin-bottom:25px;">
</div>
## **Saving shapefiles**
\

To save an **sf** object to a file, we use the function `st_write()` and specify at least two arguments, the object and a file name in quotes with the file extension. You'll also need to specify `delete_layer = TRUE` which overwrites the existing file if it already exists.  Make sure you've set your directory to the folder you want your file to be saved in.  Type in `getwd()` to see your current directory and use `setwd()` to set the directory.

Let's save *sac.metro.tracts* as a shapefile named *sacmetrotracts*.  You'll be using this file in Question 3 of Assignment 4.

```{r message=FALSE, results = FALSE}
st_write(sac.metro.tracts, "sacmetrotracts.shp", delete_layer = TRUE)
```

Check your current working directory to see if the file *sacmetrotracts.shp* is saved.

You can save your **sf** object in a number of different data formats other than `shp`.  We won't be concerned too much with these other formats, but you can see a list of them [here](https://www.gdal.org/ogr_formats.html).


<div style="margin-bottom:25px;">
</div>
## **Mapping in R**
\

Now that you've got your spatial data in and wrangled, the next natural step is to map something. There are several functions in R that can be used for mapping.  We won't go through all of them, but GWR outlines in Table 8.1 the range of mapping packages available in R.  We'll go through two of them: **ggplot2** and **tmap**.

<div style="margin-bottom:25px;">
</div>
### **ggplot**
\

The way `ggplot()` works for mapping is similar to when we used it for making graphs.  `ggplot()` is the foundation and we add elements to it using other functions.  Recall from [Lab 3](https://crd150.github.io/lab3.html) the basic `ggplot()` template.

\

````
`r ''`ggplot(data = <DATA>) +
      <GEOM_FUNCTION>(mapping = aes())
````
\



For mapping purposes,  `geom_sf()` is `<GEOM_FUNCTION>()`.  Let's first map Sacramento metropolitan area tracts.  Place the **sf** object *sac.metro.tracts* inside `ggplot()` and add `geom_sf()`.

```{r}
ggplot(sac.metro.tracts) +
  geom_sf()
``` 

Hooray! You've just made your first map in R. If you are getting the following error when you map

<br>

````
`r ''`---
Error in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y,  : 
  polygon edge not found
---
````

<br>

rerun the code.  Keep rerunning it until the error does not come up. This is an [internal issue](https://github.com/tidyverse/ggplot2/issues/2252) that has not been resolved. If you are getting an error about R not being able to find the function `geom_sf()` see [here](https://stackoverflow.com/questions/46817128/error-could-not-find-function-geom-sf?rq=1) for some guidance.

<br>

What if we wanted to map a variable, like tract median household income? Unlike with functions like `geom_histogram()` and `geom_boxplot()`, we don't specify an x and y axis.  Instead you use the argument `fill` if you want to map a variable.

Let's make a choropleth map of income, which was discussed on pages 73-77 in OSU Ch. 3.  We need to specify a numeric variable in the `fill =` argument within `geom_sf()`. 

```{r}
ggplot(sac.metro.tracts) +
  geom_sf(aes(fill = medincome))
``` 

Notice that it is difficult to see the color variation in areas with small neighborhoods because of the gray tract borders, such as in downtown Sacramento.  Eliminate the tract borders by using `color = NA` inside `geom_sf()`. 

```{r}
ggplot(sac.metro.tracts) +
  geom_sf(aes(fill = medincome), color = NA)
``` 

We make layout adjustments to the map by adding functions after `geom_sf()` using the addition operator `+`. For example, we can specify a title using the `labs()` function.  


```{r}
ggplot(sac.metro.tracts) +
  geom_sf(aes(fill = medincome), color = NA) +
  labs(title = "Median income in Sacramento Metropolitan Area Tracts")  
``` 


Don't like a blue color scale? You can change it using the `scale_fille_gradient()` function. 

```{r}
ggplot(sac.metro.tracts) +   
  geom_sf(aes(fill = medincome), color = NA) +
  scale_fill_gradient(low = "white", high = "red", na.value ="gray", name = "Median income") +  
  labs(title = "Median income in Sacramento Metropolitan Area Tracts",
       caption = "Tracts missing values are colored gray \n Source: American Community Survey") 
```

A few things to note about the above code.  First, `low = "white"` and `high = "red"` color tracts white to darker degrees of red from lowest to highest income. Second, we changed the legend title using the `name =` argument. Third, we colored tracts with missing values as gray using the argument `na.value = "gray"`. Finally, we added a caption to let the viewer know about the missing values using the `caption =` argument within `labs()`.

I'm not a big fan of the border, the gridlines, and the geographic coordinate labels.  The function `theme()` controls these features.  We eliminate these features from the map.  

```{r}
ggplot(sac.metro.tracts) +
  geom_sf(aes(fill = medincome), color = NA) +
  scale_fill_gradient(low= "white", high = "red", na.value ="gray", name ="") + 
  labs(title = "Median income in Sacramento Metropolitan Area Tracts",
       caption = "Tracts missing values are colored gray \n Source: American Community Survey") +  
  theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())
```      



<div style="margin-bottom:25px;">
</div>
### **tmap**
\

Another popular package for mapping is **tmap**. Whether one uses the **tmap** or **ggplot2** is a matter of taste, but let's spend more time on **tmap** given that our textbook resource GWR spends more attention to this package. 

Similar to **ggplot2**, **tmap** is a series of functions that build on one another. The foundation is `tm_shape()` which acts like `ggplot()`.  You then build on `tm_shape()` by adding one or more elements, in particular `tm_polygons()`. All additional functions take on the form of `tm_`.  Check the full list of `tm_` elements [here](https://www.rdocumentation.org/packages/tmap/versions/2.0/topics/tmap-element).

Let's make a choropleth map of median household income. 

```{r warning = FALSE, message = FALSE}
tm_shape(sac.metro.tracts) +
  tm_polygons(col = "medincome", style = "quantile")
```

You first put the dataset *sac.metro.tracts* inside `tm_shape()`. Because you are plotting polygons, you use `tm_polygons()` next. The argument `col = "medincome"` tells R to shade the tracts by the variable *medincome*.  The argument `style = "quantile"` tells R to break up the shading into quantiles, or equal groups of 5.  I find that this is where **tmap** offers a distinct advantage over **ggplot2** in that users have greater control over the legend and bin breaks.  **tmap** allows users to specify algorithms to automatically create breaks with the `style` argument.  Seven of the most useful break styles are described in the bullet points below (taken from GWR):

* `style = pretty`, the default setting, rounds breaks into whole numbers where possible and spaces them evenly
* `style = equal` divides input values into bins of equal range, and is appropriate for variables with a uniform distribution (not recommended for variables with a skewed distribution as the resulting map may end-up having little color diversity)
* `style = quantile` ensures the same number of observations fall into each category (with the potential down side that bin ranges can vary widely)
* `style = jenks` identifies groups of similar values in the data and maximizes the differences between categories
* `style = cont` (and `order`) present a large number of colors over continuous color field, and are particularly suited for continuous rasters (order can help visualize skewed distributions)
* `style = sd` divides the values by standard deviations above and below the mean.
* `style = cat` was designed to represent categorical values and assures that each category receives a unique color

We can change the color scheme and tract borders using arguments within `tm_polygons()`. The argument `palette =` defines the color ranges associated with the bins and determined by the `style` arguments.  

```{r warning = FALSE, message = FALSE}
tm_shape(sac.metro.tracts) +
  tm_polygons(col = "medincome", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "Median income") 
```

Here, we used the color scheme "Reds". See Ch. 8.2.4 in GWR for a fuller discussion on color and other schemes you can specify.

Also notice two additional arguments in the above code. `border.alpha` specifies the transparency of the polygon borders, which we set to 0 to indicate totally transparent. This eliminates the border colors between tracts, like `color = NA` inside `geom_sf()` did in `ggplot()`. The argument `title` specifies the title of the legend like `name =` in `ggplot()`.

<div style="margin-bottom:25px;">
</div>
### **Scale bar and arrow**
\

We need to add other key elements to the map. Here is where we start adding layout functions using the `+` operator.  First, the scale bar, which you can add using the function `tm_scale_bar()`

```{r warning = FALSE, message = FALSE}
tm_shape(sac.metro.tracts, unit = "mi") +
  tm_polygons(col = "medincome", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "Median income") +
  tm_scale_bar(breaks = c(0, 10, 20), size = 1, position = c("left", "bottom")) 
```

The argument `breaks` tells R the distances to break up and end the bar.  Make sure you use reasonable break points - the Sacramento metro area is not, for example, 200 miles wide, so you should not use `c(0,10,200)` (try it and see what happens. You won't like it). Note that the scale is in miles (were in America!).  The default is in kilometers (the rest of the world!), but you can specify the units within `tm_shape()` using the argument `unit`.  Here, we used `unit = "mi"`.  The `position =` argument specifies to locate the scale bar on the bottom left of the map.

<br>

The next element is the north arrow, which we can add using the function `tm_compass()`.  You can control for the type, size and location of the arrow within this function.  We place a 4-star arrow on the top left of the map.

```{r warning = FALSE, message = FALSE}
tm_shape(sac.metro.tracts, unit = "mi") +
  tm_polygons(col = "medincome", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "Median income") +
  tm_scale_bar(breaks = c(0, 10, 20), size = 1, position = c("left", "bottom")) +
  tm_compass(type = "4star", position = c("left", "top")) 
```

<div style="margin-bottom:25px;">
</div>
### **Map layout**
\

We can make the map *prettier* by changing a variety of layout settings using the function `tm_layout()`.  This function is similar to `theme()` in `ggplot()`.  Check the help documentation for `tm_layout()` to see the complete list of settings.  Also see examples in Ch. 8.2.5 in GWR.  Let's change a few things to our map.

```{r, message=FALSE, warning = FALSE, results = "hide"}
sac.map <- tm_shape(sac.metro.tracts, unit = "mi") +
  tm_polygons(col = "medincome", style = "quantile",palette = "Reds", 
              border.alpha = 0) +
  tm_scale_bar(breaks = c(0, 10, 20), size = 1, position = c("left", "bottom")) +
  tm_compass(type = "4star", position = c("left", "top")) + 
  tm_layout(main.title = "Median income in Sacramento Metropolitan Area Tracts",         main.title.size = 0.95, frame = FALSE)
  
sac.map
```

We did a few things within the `tm_layout()` function

* We added a title using the argument `main.title`
* We made sure the title fits inside the map using `main.title.size`
* We eliminated the frame around the map using the argument `frame = FALSE`

Also notice that we stored the map into an object called *sac.map*.  R is an object-oriented language, so *everything* you *make* in R are objects that can be stored for future manipulation.  This includes maps.  You should see *sac.map* in your Environment window. By storing the map, can access it anytime during your current R session.


<div style="margin-bottom:25px;">
</div>    
### **Saving maps**
\

You can save your maps a couple of ways.

1. On the plotting screen where the map is shown, click on *Export* and save it as either an image or pdf file.
2. Use the function `tmap_save()`

For option 2, we can save the map object *sac.map* as such

```{r warning=FALSE, message=FALSE}
tmap_save(sac.map, "sacmetroinc.jpg")
```

Specify the **tmap** object and a filename with an extension. It supports `pdf`, `eps`, `svg`, `wmf`, `png`, `jpg`, `bmp` and `tiff`.  The default is `png`.  Also make sure you've set your directory to the folder that you want your map to be saved in.  

<div style="margin-bottom:25px;">
</div>
### **Interactive maps**
\

So far we've created static maps. That is, maps that don't "move".  But, we're all likely used to Google or Bing maps - maps that we can move around and zoom into.  You can make interactive maps in R using the package **tmap**.  Here is another benefit of using **tmap** over **ggplot2** - the latter does not provide interactivity.

To make your **tmap** object interactive, use the function `tmap_mode()`

```{r, warning = FALSE, message = FALSE}
tmap_mode("view")
```

Now that the interactive mode has been ‘turned on’, all maps produced with `tm_shape()` will launch. Let's view our saved *sac.map* interactively.

```{r, warning = FALSE, message = FALSE}
sac.map
```

Click on ![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/zoom.png) above the map and a larger window should open up. 

Besides interactivity, another important benefit of `tmap_mode()` is that it provides a basemap.  The function of a basemap is to provide background detail necessary to orient the location of the map.  In the static maps we produced above, the Sacramento metropolitan area was sort of floating in white space.  As you can see in the interactive map we've added geographic context to the surrounding area. 

The default basemap in `tmap_mode()` is CartoDB.Positron.  You can change the basemap through the `tm_view()` function.  For example, let's change the basemap to an [OpenStreetMap](https://www.openstreetmap.org/).

```{r warning=FALSE, message=FALSE}
sac.map + tm_view(basemaps="OpenStreetMap")
```

For a complete list of basemaps with previews, see [here](http://leaflet-extras.github.io/leaflet-providers/preview/).  There are a lot of cool ones, so please test them out.

You can save your interactive map using the same methods described above. To switch back to plotting mode (noninteractive), type in 

```{r}
tmap_mode("plot")
```


<div style="margin-bottom:25px;">
</div>
## **Assignment 4**
\

Download and open the [Assignment 4 R Markdown Script](https://raw.githubusercontent.com/crd150/data/master/yourLastName_firstInitial_asgn04.Rmd). Any response requiring a data analysis task  must be supported by code you generate to produce your result. Just examining your various objects in the “Environment” section of R Studio is insufficient—you must use scripted commands. Submit the `Rmd` and its knitted `html` files on Canvas.

1. Describe which "pitfalls" - Spatial Autocorrelation, the Modifiable Areal Unit Problem, the Ecological Fallacy, Scale, Nonuniformity of Space, and Edge Effects - each of the following scenarios fall under. Briefly explain your answer. (1 point each)

a. The correlation between percent non-Hispanic black and percent poverty is 0.8 at the Census block level, 0.4 at the block group level, 0.2 at the tract level, and -0.2 at the county level.
b. The scatterplots below show the same data - each point represents an individual person plotted based on their values for *x* and *y*.  The right scatterplot color codes each individual based on their county of residence, with correlations calculated for each county *Z*.

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/fig1hw4.png)


</center>


c. A researcher concludes that full-service banks in Los Angeles are spatially inaccessible to Hispanic neighborhoods. The researcher bases his conclusion on the location of banks within Los Angeles City boundaries.  The map below shows Los Angeles City census tracts by percent Hispanic and the location of full-service banks

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/fig3hw4.png)


</center>

d. The two figures below show the same area, but with neighborhoods defined differently. The values represent the mean of a variable.  

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/fig4hw4.png)


</center>

<br>

2. The table below contains the spatial coordinates of 4 neighborhoods.  You do not have to use R to answer the following questions, but you can use it as a calculator to show your work (if you get a value wrong but show work, you'll get partial points).

```{r message = FALSE, warning = FALSE, echo=FALSE}
library(kableExtra)
library(knitr)
table1 <- data.frame(Neighborhood = c(1,2,3,4), x = c(2,4,4,6), y = c(1,4,8,2))
kable(table1) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"),full_width = F) %>%
    column_spec(2, width = "5em")
```

a. Create a distance matrix **D** using Euclidean distance. Round your values to the one digit after the decimal point. (2 points)

$$D = \begin{bmatrix} &  &  & \\
 &  &  & \\
 &  &  & \\
 &  &  &
\end{bmatrix}$$


b. Create an adjacency matrix **A** using the rule for adjacency that two neighborhoods must be less than 5 distance units apart. (2 points)

$$A = \begin{bmatrix} &  &  & \\
 &  &  & \\
 &  &  & \\
 &  &  &
\end{bmatrix}$$

c. Create an interaction matrix **W** with the following rules: (1) neighborhoods interact if they are adjacent; (2) weights are based on inverse distance; (3) weights sum up to 1 for each row. Round your values to two digits after the decimal point. (2 points)

$$W = \begin{bmatrix} &  &  & \\
 &  &  & \\
 &  &  & \\
 &  &  &
\end{bmatrix}$$

<br>

3. One can easily lie (or distort the story) with maps. A common trick for spatially misrepresenting numeric data is to choose a classification scheme that aligns with your pre-conceived story. In the lab guide, we showed quantile breaks of median income in Sacramento. Using the object *sacmetrotracts.shp* you saved in Lab, produce maps using three other classifications. Does your general impression of where high and low income neighborhoods are located in the metropolitan area change across the different classifications? (3 points)

<br>

4. This [article](http://www.latimes.com/nation/la-na-houston-diversity-2017-htmlstory.html) claims that Houston is the most diverse city in the United States.  Let's descriptively examine this claim. You will be using the shapefile *houstoncityrace.shp*.  I zipped the file up and loaded it onto GitHub.  Use the following code to read the file into R.  Make sure to change `###your object name here### ` with an actual object name.

````
`r ''`setwd("insert your pathway here")
download.file(url = "https://raw.githubusercontent.com/crd150/data/master/assign4files.zip", destfile = "assign4files.zip")
unzip(zipfile = "assign4files.zip")

###your object name here### <- st_read("houstoncityrace.shp", stringsAsFactors = FALSE)
````

The file contains 2013-17 American Community Survey census tract data for percent poverty, percent non-Hispanic white, percent non-Hispanic black, percent non-Hispanic Asian, and percent Hispanic. The file is clean and ready for analysis. A record layout of the data can be found [here](https://raw.githubusercontent.com/crd150/data/master/week4assgn_record_layout.txt). 

a. The racial composition in the United States is 62.0% non-Hispanic white, 12.3% non-Hispanic black, 5.2% non-Hispanic Asian, and 17.3% Hispanic. What is the average percent non-Hispanic white, percent non-Hispanic black, percent non-Hispanic Asian, and percent Hispanic in Houston neighborhoods? Based on these percentages, would you agree with the article that Houston is a diverse city? (1 point)

b. Create presentation-ready maps of percent non-Hispanic black, non-Hispanic white, non-Hispanic Asian, and Hispanic using quantile breaks.  (2 points)

c. From (b), is your general impression that white residents are clustered? What about the other three race/ethnic groups?  Based on these maps, would you agree with the article that Houston is a diverse city? Would you modify this claim? If so, how? (2 points)

d. Create a presentation-ready map of the poverty rate. Based on this map and the maps you constructed in (b), briefly describe the spatial association between neighborhood poverty and race/ethnicity in Houston. (2 points)


***


Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)